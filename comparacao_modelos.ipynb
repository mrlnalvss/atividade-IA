{"cells":[{"cell_type":"markdown","id":"53fae8af","metadata":{"id":"53fae8af"},"source":["# ü§ñ Compara√ß√£o de Modelos LLM com HuggingFace\n","**Grupo:** Felipe Terem, Guilherme Ayres, Henrique Martins, Jo√£o Pedro Loureiro e Marlon Alves  \n","**T√≥pico:** Compara√ß√£o de Modelos de Linguagem\n","\n","---\n","\n","## üìã Objetivo do Projeto\n","\n","Este notebook compara **2 modelos LLM** do HuggingFace em m√∫ltiplas dimens√µes:\n","- ‚è±Ô∏è **Velocidade** de resposta\n","- üéØ **Qualidade** das respostas\n","- üíæ **Uso de mem√≥ria**\n","- üìä **Benchmarks** oficiais\n","- üåç **Capacidades** espec√≠ficas\n","\n","---\n","\n","## üî¨ Modelos Selecionados\n","\n","| Modelo | Desenvolvedor | Par√¢metros | Tipo |\n","|--------|---------------|------------|------|\n","| **Flan-T5-Small** | Google | ~80M | Text-to-Text |\n","| **Flan-T5-Base** | Google | ~250M | Text-to-Text |\n","\n","---"]},{"cell_type":"markdown","id":"33fcc5ae","metadata":{"id":"33fcc5ae"},"source":["## 1Ô∏è‚É£ Instala√ß√£o de Depend√™ncias"]},{"cell_type":"code","execution_count":null,"id":"e06e636b","metadata":{"id":"e06e636b"},"outputs":[],"source":["# Instala√ß√£o de bibliotecas necess√°rias\n","!pip install transformers torch sentencepiece accelerate matplotlib pandas -q\n","\n","print(\"‚úÖ Bibliotecas instaladas com sucesso!\")"]},{"cell_type":"markdown","id":"bdbd65a6","metadata":{"id":"bdbd65a6"},"source":["## 2Ô∏è‚É£ Importa√ß√£o de Bibliotecas"]},{"cell_type":"code","execution_count":null,"id":"839d63b6","metadata":{"id":"839d63b6"},"outputs":[],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n","import time\n","import psutil\n","import os\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","print(\"‚úÖ Bibliotecas importadas!\")\n","print(f\"üî• PyTorch vers√£o: {torch.__version__}\")\n","print(f\"üíª CUDA dispon√≠vel: {torch.cuda.is_available()}\")"]},{"cell_type":"markdown","id":"f9ac5c1d","metadata":{"id":"f9ac5c1d"},"source":["## 3Ô∏è‚É£ Carregamento dos Modelos\n","\n","Vamos carregar os dois modelos do HuggingFace Hub."]},{"cell_type":"code","execution_count":null,"id":"3434757b","metadata":{"id":"3434757b"},"outputs":[],"source":["print(\"üîÑ Carregando modelos do HuggingFace Hub...\\n\")\n","\n","# Informa√ß√µes dos modelos\n","modelos_info = {\n","    \"Flan-T5-Small\": \"google/flan-t5-small\",\n","    \"Flan-T5-Base\": \"google/flan-t5-base\"\n","}\n","\n","# Dicion√°rio para armazenar os modelos carregados\n","modelos = {}\n","tokenizers = {}\n","pipelines = {}\n","\n","# Carregar cada modelo\n","for nome, model_id in modelos_info.items():\n","    print(f\"üì¶ Carregando {nome} ({model_id})...\")\n","\n","    try:\n","        # Carregar tokenizer\n","        tokenizers[nome] = AutoTokenizer.from_pretrained(model_id)\n","\n","        # Carregar modelo\n","        modelos[nome] = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n","\n","        # Criar pipeline\n","        pipelines[nome] = pipeline(\n","            \"text2text-generation\",\n","            model=modelos[nome],\n","            tokenizer=tokenizers[nome],\n","            device=-1  # CPU\n","        )\n","\n","        # Contar par√¢metros\n","        num_params = sum(p.numel() for p in modelos[nome].parameters())\n","\n","        print(f\"   ‚úÖ {nome} carregado!\")\n","        print(f\"   üìä Par√¢metros: {num_params:,}\")\n","        print(f\"   üíæ Tamanho em mem√≥ria: ~{num_params * 4 / (1024**2):.1f} MB\\n\")\n","\n","    except Exception as e:\n","        print(f\"   ‚ùå Erro ao carregar {nome}: {str(e)}\\n\")\n","\n","print(\"=\"*70)\n","print(\"‚úÖ Todos os modelos carregados com sucesso!\")\n","print(\"=\"*70)"]},{"cell_type":"markdown","id":"ca625aee","metadata":{"id":"ca625aee"},"source":["## 4Ô∏è‚É£ Defini√ß√£o dos Testes\n","\n","Vamos criar diferentes categorias de testes para avaliar os modelos de forma abrangente."]},{"cell_type":"code","execution_count":null,"id":"60511191","metadata":{"id":"60511191"},"outputs":[],"source":["# Conjunto de testes organizados por categoria\n","testes = {\n","    \"üìö Conhecimento Geral\": [\n","        \"O que √© intelig√™ncia artificial?\",\n","        \"Quem foi Albert Einstein?\",\n","        \"Qual √© a capital do Brasil?\",\n","        \"O que √© o HuggingFace?\"\n","    ],\n","\n","    \"üî¢ Racioc√≠nio Matem√°tico\": [\n","        \"Quanto √© 15 mais 27?\",\n","        \"Calcule 8 vezes 9.\",\n","        \"Quanto √© 100 dividido por 4?\",\n","        \"Se eu tenho 50 reais e gasto 23, quanto sobra?\"\n","    ],\n","\n","    \"üåç Tradu√ß√£o\": [\n","        \"Traduza para ingl√™s: Bom dia, como voc√™ est√°?\",\n","        \"Traduza para franc√™s: Eu gosto de programar.\",\n","        \"Traduza para espanhol: O livro est√° na mesa.\"\n","    ],\n","\n","    \"üí° Racioc√≠nio L√≥gico\": [\n","        \"Se todos os gatos s√£o animais e Rex √© um gato, o que podemos concluir?\",\n","        \"Complete o padr√£o: 2, 4, 8, 16, ?\",\n","        \"Qual √© maior: 0.5 ou 0.05?\"\n","    ],\n","\n","    \"üé® Criatividade\": [\n","        \"Crie um slogan para uma empresa de tecnologia.\",\n","        \"Complete a frase: A melhor forma de aprender √©...\",\n","        \"D√™ um nome criativo para um rob√¥ assistente.\"\n","    ]\n","}\n","\n","print(\"‚úÖ Testes definidos!\")\n","print(f\"\\nüìä Total de categorias: {len(testes)}\")\n","print(f\"üìù Total de perguntas: {sum(len(v) for v in testes.values())}\")\n","\n","# Mostrar resumo\n","print(\"\\n\" + \"=\"*70)\n","print(\"üìã CATEGORIAS DE TESTE:\")\n","print(\"=\"*70)\n","for categoria, perguntas in testes.items():\n","    print(f\"\\n{categoria}\")\n","    for i, pergunta in enumerate(perguntas, 1):\n","        print(f\"  {i}. {pergunta}\")"]},{"cell_type":"markdown","id":"b41eda37","metadata":{"id":"b41eda37"},"source":["## 5Ô∏è‚É£ Fun√ß√£o de Compara√ß√£o\n","\n","Vamos criar uma fun√ß√£o que executa os testes e coleta m√©tricas detalhadas."]},{"cell_type":"code","execution_count":null,"id":"892cd28e","metadata":{"id":"892cd28e"},"outputs":[],"source":["def comparar_modelos(pergunta, pipelines, max_length=100, verbose=True):\n","    \"\"\"\n","    Compara a resposta de m√∫ltiplos modelos para uma pergunta.\n","\n","    Args:\n","        pergunta: Pergunta a ser respondida\n","        pipelines: Dicion√°rio com os pipelines dos modelos\n","        max_length: Tamanho m√°ximo da resposta\n","        verbose: Se True, imprime informa√ß√µes detalhadas\n","\n","    Returns:\n","        DataFrame com os resultados comparativos\n","    \"\"\"\n","    resultados = []\n","\n","    if verbose:\n","        print(f\"\\n{'='*70}\")\n","        print(f\"‚ùì PERGUNTA: {pergunta}\")\n","        print(f\"{'='*70}\\n\")\n","\n","    for nome_modelo, pipe in pipelines.items():\n","        if verbose:\n","            print(f\"ü§ñ Testando {nome_modelo}...\")\n","\n","        # Medir tempo de resposta\n","        inicio = time.time()\n","\n","        try:\n","            # Gerar resposta\n","            resposta = pipe(\n","                pergunta,\n","                max_length=max_length,\n","                do_sample=False,\n","                temperature=0.7\n","            )[0]['generated_text']\n","\n","            tempo_resposta = time.time() - inicio\n","\n","            # Calcular tokens\n","            tokens_entrada = len(tokenizers[nome_modelo].encode(pergunta))\n","            tokens_saida = len(tokenizers[nome_modelo].encode(resposta))\n","\n","            # Armazenar resultado\n","            resultado = {\n","                'Modelo': nome_modelo,\n","                'Resposta': resposta,\n","                'Tempo (s)': round(tempo_resposta, 3),\n","                'Tokens Entrada': tokens_entrada,\n","                'Tokens Sa√≠da': tokens_saida,\n","                'Tamanho Resposta': len(resposta),\n","                'Velocidade (tokens/s)': round(tokens_saida / tempo_resposta, 2) if tempo_resposta > 0 else 0\n","            }\n","\n","            resultados.append(resultado)\n","\n","            if verbose:\n","                print(f\"   ‚úÖ Resposta: {resposta}\")\n","                print(f\"   ‚è±Ô∏è  Tempo: {tempo_resposta:.3f}s\")\n","                print(f\"   üìä Tokens: {tokens_entrada} entrada ‚Üí {tokens_saida} sa√≠da\")\n","                print(f\"   üöÄ Velocidade: {resultado['Velocidade (tokens/s)']} tokens/s\\n\")\n","\n","        except Exception as e:\n","            if verbose:\n","                print(f\"   ‚ùå Erro: {str(e)}\\n\")\n","\n","            resultados.append({\n","                'Modelo': nome_modelo,\n","                'Resposta': f\"ERRO: {str(e)}\",\n","                'Tempo (s)': 0,\n","                'Tokens Entrada': 0,\n","                'Tokens Sa√≠da': 0,\n","                'Tamanho Resposta': 0,\n","                'Velocidade (tokens/s)': 0\n","            })\n","\n","    return pd.DataFrame(resultados)\n","\n","print(\"‚úÖ Fun√ß√£o de compara√ß√£o criada!\")"]},{"cell_type":"markdown","id":"fdc4334d","metadata":{"id":"fdc4334d"},"source":["## 6Ô∏è‚É£ Execu√ß√£o dos Testes Comparativos\n","\n","Agora vamos executar todos os testes e coletar os resultados!"]},{"cell_type":"code","execution_count":null,"id":"695f0687","metadata":{"id":"695f0687"},"outputs":[],"source":["print(\"\\n\" + \"=\"*70)\n","print(\"üß™ INICIANDO BATERIA DE TESTES COMPARATIVOS\")\n","print(\"=\"*70)\n","\n","# Armazenar todos os resultados\n","todos_resultados = []\n","resultados_por_categoria = {}\n","\n","# Executar testes por categoria\n","for categoria, perguntas in testes.items():\n","    print(f\"\\n\\n{'#'*70}\")\n","    print(f\"{categoria}\")\n","    print(f\"{'#'*70}\")\n","\n","    resultados_categoria = []\n","\n","    for i, pergunta in enumerate(perguntas, 1):\n","        print(f\"\\nüìù Teste {i}/{len(perguntas)}\")\n","\n","        # Executar compara√ß√£o\n","        df_resultado = comparar_modelos(pergunta, pipelines, verbose=True)\n","        df_resultado['Categoria'] = categoria\n","        df_resultado['Pergunta'] = pergunta\n","\n","        # Armazenar\n","        resultados_categoria.append(df_resultado)\n","        todos_resultados.append(df_resultado)\n","\n","        # Pequena pausa para n√£o sobrecarregar\n","        time.sleep(0.5)\n","\n","    # Consolidar resultados da categoria\n","    resultados_por_categoria[categoria] = pd.concat(resultados_categoria, ignore_index=True)\n","\n","# Consolidar todos os resultados\n","df_completo = pd.concat(todos_resultados, ignore_index=True)\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"‚úÖ TODOS OS TESTES CONCLU√çDOS!\")\n","print(\"=\"*70)\n","print(f\"\\nüìä Total de testes realizados: {len(df_completo)}\")"]},{"cell_type":"markdown","id":"b10be8a2","metadata":{"id":"b10be8a2"},"source":["## 7Ô∏è‚É£ An√°lise Comparativa - Velocidade\n","\n","Vamos analisar qual modelo √© mais r√°pido em cada categoria."]},{"cell_type":"code","execution_count":null,"id":"cb05b570","metadata":{"id":"cb05b570"},"outputs":[],"source":["print(\"\\n\" + \"=\"*70)\n","print(\"‚ö° AN√ÅLISE DE VELOCIDADE\")\n","print(\"=\"*70)\n","\n","# Calcular estat√≠sticas de tempo por modelo\n","tempo_por_modelo = df_completo.groupby('Modelo')['Tempo (s)'].agg([\n","    ('M√©dia', 'mean'),\n","    ('Mediana', 'median'),\n","    ('M√≠nimo', 'min'),\n","    ('M√°ximo', 'max'),\n","    ('Desvio Padr√£o', 'std')\n","]).round(3)\n","\n","print(\"\\nüìä Estat√≠sticas de Tempo de Resposta (segundos):\\n\")\n","print(tempo_por_modelo)\n","\n","# Tempo m√©dio por categoria\n","print(\"\\n\" + \"-\"*70)\n","print(\"‚è±Ô∏è  TEMPO M√âDIO POR CATEGORIA:\")\n","print(\"-\"*70)\n","\n","for categoria in testes.keys():\n","    df_cat = df_completo[df_completo['Categoria'] == categoria]\n","    print(f\"\\n{categoria}\")\n","\n","    for modelo in modelos_info.keys():\n","        df_modelo = df_cat[df_cat['Modelo'] == modelo]\n","        tempo_medio = df_modelo['Tempo (s)'].mean()\n","        print(f\"   ‚Ä¢ {modelo}: {tempo_medio:.3f}s\")\n","\n","# Visualiza√ß√£o\n","plt.figure(figsize=(12, 6))\n","\n","# Gr√°fico de barras - tempo m√©dio\n","modelos_nomes = df_completo['Modelo'].unique()\n","tempos_medios = [df_completo[df_completo['Modelo'] == m]['Tempo (s)'].mean()\n","                 for m in modelos_nomes]\n","\n","plt.subplot(1, 2, 1)\n","bars = plt.bar(modelos_nomes, tempos_medios, color=['#4CAF50', '#2196F3'])\n","plt.ylabel('Tempo M√©dio (segundos)', fontsize=12)\n","plt.title('‚è±Ô∏è  Tempo M√©dio de Resposta', fontsize=14, fontweight='bold')\n","plt.xticks(rotation=45, ha='right')\n","\n","# Adicionar valores nas barras\n","for i, (bar, tempo) in enumerate(zip(bars, tempos_medios)):\n","    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n","             f'{tempo:.3f}s', ha='center', va='bottom', fontweight='bold')\n","\n","# Gr√°fico de velocidade (tokens/s)\n","plt.subplot(1, 2, 2)\n","velocidades_medias = [df_completo[df_completo['Modelo'] == m]['Velocidade (tokens/s)'].mean()\n","                      for m in modelos_nomes]\n","\n","bars = plt.bar(modelos_nomes, velocidades_medias, color=['#FF9800', '#9C27B0'])\n","plt.ylabel('Tokens por Segundo', fontsize=12)\n","plt.title('üöÄ Velocidade de Gera√ß√£o', fontsize=14, fontweight='bold')\n","plt.xticks(rotation=45, ha='right')\n","\n","for i, (bar, vel) in enumerate(zip(bars, velocidades_medias)):\n","    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n","             f'{vel:.1f}', ha='center', va='bottom', fontweight='bold')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Identificar o mais r√°pido\n","modelo_mais_rapido = modelos_nomes[tempos_medios.index(min(tempos_medios))]\n","diferenca_percentual = ((max(tempos_medios) - min(tempos_medios)) / max(tempos_medios)) * 100\n","\n","print(f\"\\nüèÜ VENCEDOR EM VELOCIDADE: {modelo_mais_rapido}\")\n","print(f\"üìä Diferen√ßa: {diferenca_percentual:.1f}% mais r√°pido que o outro modelo\")"]},{"cell_type":"markdown","id":"e0b2579d","metadata":{"id":"e0b2579d"},"source":["## 8Ô∏è‚É£ An√°lise Comparativa - Qualidade das Respostas\n","\n","Vamos examinar alguns exemplos de respostas lado a lado."]},{"cell_type":"code","execution_count":null,"id":"1d405b0c","metadata":{"id":"1d405b0c"},"outputs":[],"source":["print(\"\\n\" + \"=\"*70)\n","print(\"üéØ AN√ÅLISE DE QUALIDADE DAS RESPOSTAS\")\n","print(\"=\"*70)\n","\n","# Selecionar perguntas interessantes para compara√ß√£o lado a lado\n","perguntas_destaque = [\n","    \"O que √© intelig√™ncia artificial?\",\n","    \"Quanto √© 15 mais 27?\",\n","    \"Traduza para ingl√™s: Bom dia, como voc√™ est√°?\",\n","    \"Complete o padr√£o: 2, 4, 8, 16, ?\"\n","]\n","\n","print(\"\\nüìã COMPARA√á√ÉO LADO A LADO:\\n\")\n","\n","for pergunta in perguntas_destaque:\n","    df_pergunta = df_completo[df_completo['Pergunta'] == pergunta]\n","\n","    if len(df_pergunta) > 0:\n","        print(\"=\"*70)\n","        print(f\"‚ùì {pergunta}\")\n","        print(\"=\"*70)\n","\n","        for _, row in df_pergunta.iterrows():\n","            print(f\"\\nü§ñ {row['Modelo']}:\")\n","            print(f\"   Resposta: {row['Resposta']}\")\n","            print(f\"   Tempo: {row['Tempo (s)']}s\")\n","            print(f\"   Tamanho: {row['Tamanho Resposta']} caracteres\")\n","\n","        print()\n","\n","# An√°lise de tamanho de respostas\n","print(\"\\n\" + \"-\"*70)\n","print(\"üìè AN√ÅLISE DE TAMANHO DAS RESPOSTAS:\")\n","print(\"-\"*70)\n","\n","tamanho_por_modelo = df_completo.groupby('Modelo')['Tamanho Resposta'].agg([\n","    ('M√©dia', 'mean'),\n","    ('M√≠nimo', 'min'),\n","    ('M√°ximo', 'max')\n","]).round(1)\n","\n","print(\"\\n\", tamanho_por_modelo)\n","\n","# Visualiza√ß√£o\n","plt.figure(figsize=(10, 6))\n","\n","for i, modelo in enumerate(modelos_nomes):\n","    df_modelo = df_completo[df_completo['Modelo'] == modelo]\n","    tamanhos = df_modelo['Tamanho Resposta'].values\n","    plt.hist(tamanhos, bins=15, alpha=0.6, label=modelo, edgecolor='black')\n","\n","plt.xlabel('Tamanho da Resposta (caracteres)', fontsize=12)\n","plt.ylabel('Frequ√™ncia', fontsize=12)\n","plt.title('üìè Distribui√ß√£o do Tamanho das Respostas', fontsize=14, fontweight='bold')\n","plt.legend()\n","plt.grid(axis='y', alpha=0.3)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","id":"888b391b","metadata":{"id":"888b391b"},"source":["## 9Ô∏è‚É£ An√°lise por Categoria de Teste\n","\n","Vamos ver qual modelo se saiu melhor em cada tipo de tarefa."]},{"cell_type":"code","execution_count":null,"id":"43d3657d","metadata":{"id":"43d3657d"},"outputs":[],"source":["print(\"\\n\" + \"=\"*70)\n","print(\"üìä DESEMPENHO POR CATEGORIA\")\n","print(\"=\"*70)\n","\n","# Criar matriz de compara√ß√£o por categoria\n","categorias = list(testes.keys())\n","dados_comparacao = []\n","\n","for categoria in categorias:\n","    df_cat = df_completo[df_completo['Categoria'] == categoria]\n","\n","    linha = {'Categoria': categoria.replace('üìö ', '').replace('üî¢ ', '').replace('üåç ', '').replace('üí° ', '').replace('üé® ', '')}\n","\n","    for modelo in modelos_nomes:\n","        df_modelo = df_cat[df_cat['Modelo'] == modelo]\n","        tempo_medio = df_modelo['Tempo (s)'].mean()\n","        linha[modelo] = f\"{tempo_medio:.3f}s\"\n","\n","    dados_comparacao.append(linha)\n","\n","df_comparacao_cat = pd.DataFrame(dados_comparacao)\n","\n","print(\"\\n‚è±Ô∏è  TEMPO M√âDIO POR CATEGORIA:\\n\")\n","print(df_comparacao_cat.to_string(index=False))\n","\n","# Gr√°fico de compara√ß√£o por categoria\n","plt.figure(figsize=(14, 6))\n","\n","x = range(len(categorias))\n","width = 0.35\n","\n","for i, modelo in enumerate(modelos_nomes):\n","    tempos = []\n","    for categoria in categorias:\n","        df_cat = df_completo[df_completo['Categoria'] == categoria]\n","        df_modelo = df_cat[df_cat['Modelo'] == modelo]\n","        tempo = df_modelo['Tempo (s)'].mean()\n","        tempos.append(tempo)\n","\n","    offset = width * (i - len(modelos_nomes)/2 + 0.5)\n","    plt.bar([p + offset for p in x], tempos, width,\n","            label=modelo, alpha=0.8)\n","\n","plt.xlabel('Categoria de Teste', fontsize=12)\n","plt.ylabel('Tempo M√©dio (s)', fontsize=12)\n","plt.title('‚è±Ô∏è  Tempo M√©dio por Categoria de Teste', fontsize=14, fontweight='bold')\n","plt.xticks(x, [cat.split()[1] if len(cat.split()) > 1 else cat\n","               for cat in categorias], rotation=45, ha='right')\n","plt.legend()\n","plt.grid(axis='y', alpha=0.3)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","id":"f1f9d70e","metadata":{"id":"f1f9d70e"},"source":["## üîü An√°lise de Recursos Computacionais\n","\n","Vamos comparar o uso de mem√≥ria e tamanho dos modelos."]},{"cell_type":"code","execution_count":null,"id":"9f9be491","metadata":{"id":"9f9be491"},"outputs":[],"source":["print(\"\\n\" + \"=\"*70)\n","print(\"üíæ AN√ÅLISE DE RECURSOS COMPUTACIONAIS\")\n","print(\"=\"*70)\n","\n","# Informa√ß√µes dos modelos\n","recursos = []\n","\n","for nome, modelo in modelos.items():\n","    # Contar par√¢metros\n","    num_params = sum(p.numel() for p in modelo.parameters())\n","    num_params_treinaveis = sum(p.numel() for p in modelo.parameters() if p.requires_grad)\n","\n","    # Estimar tamanho em disco (bytes)\n","    tamanho_mb = (num_params * 4) / (1024 ** 2)  # 4 bytes por par√¢metro (float32)\n","\n","    recursos.append({\n","        'Modelo': nome,\n","        'Total de Par√¢metros': f\"{num_params:,}\",\n","        'Par√¢metros Trein√°veis': f\"{num_params_treinaveis:,}\",\n","        'Tamanho Estimado (MB)': f\"{tamanho_mb:.1f}\",\n","        'Tamanho Estimado (GB)': f\"{tamanho_mb/1024:.2f}\"\n","    })\n","\n","df_recursos = pd.DataFrame(recursos)\n","\n","print(\"\\nüìä ESPECIFICA√á√ïES DOS MODELOS:\\n\")\n","print(df_recursos.to_string(index=False))\n","\n","# Compara√ß√£o visual\n","fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n","\n","# Gr√°fico 1: N√∫mero de par√¢metros\n","ax1 = axes[0]\n","params = [sum(p.numel() for p in modelos[nome].parameters()) / 1_000_000\n","          for nome in modelos_nomes]\n","bars = ax1.bar(modelos_nomes, params, color=['#E91E63', '#3F51B5'])\n","ax1.set_ylabel('Milh√µes de Par√¢metros', fontsize=12)\n","ax1.set_title('üìä Quantidade de Par√¢metros', fontsize=14, fontweight='bold')\n","ax1.tick_params(axis='x', rotation=45)\n","\n","for bar, param in zip(bars, params):\n","    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n","             f'{param:.1f}M', ha='center', va='bottom', fontweight='bold')\n","\n","# Gr√°fico 2: Tamanho em disco\n","ax2 = axes[1]\n","tamanhos = [(sum(p.numel() for p in modelos[nome].parameters()) * 4) / (1024**2)\n","            for nome in modelos_nomes]\n","bars = ax2.bar(modelos_nomes, tamanhos, color=['#009688', '#FF5722'])\n","ax2.set_ylabel('Megabytes (MB)', fontsize=12)\n","ax2.set_title('üíæ Tamanho em Disco', fontsize=14, fontweight='bold')\n","ax2.tick_params(axis='x', rotation=45)\n","\n","for bar, tam in zip(bars, tamanhos):\n","    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10,\n","             f'{tam:.0f}MB', ha='center', va='bottom', fontweight='bold')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","# Calcular efici√™ncia (velocidade / tamanho)\n","print(\"\\n\" + \"-\"*70)\n","print(\"‚ö° AN√ÅLISE DE EFICI√äNCIA:\")\n","print(\"-\"*70)\n","\n","for i, nome in enumerate(modelos_nomes):\n","    tempo_medio = df_completo[df_completo['Modelo'] == nome]['Tempo (s)'].mean()\n","    num_params = sum(p.numel() for p in modelos[nome].parameters()) / 1_000_000\n","    eficiencia = num_params / tempo_medio if tempo_medio > 0 else 0\n","\n","    print(f\"\\n{nome}:\")\n","    print(f\"   ‚Ä¢ Par√¢metros: {num_params:.1f}M\")\n","    print(f\"   ‚Ä¢ Tempo m√©dio: {tempo_medio:.3f}s\")\n","    print(f\"   ‚Ä¢ Efici√™ncia: {eficiencia:.1f} M-params/segundo\")"]},{"cell_type":"markdown","id":"5784ba0e","metadata":{"id":"5784ba0e"},"source":["## 1Ô∏è‚É£1Ô∏è‚É£ Resumo Final e Conclus√µes\n","\n","Vamos consolidar todas as an√°lises e determinar qual modelo √© melhor em cada aspecto."]},{"cell_type":"code","execution_count":null,"id":"bf352ddc","metadata":{"id":"bf352ddc"},"outputs":[],"source":["print(\"\\n\" + \"=\"*70)\n","print(\"üèÜ RESUMO FINAL DA COMPARA√á√ÉO\")\n","print(\"=\"*70)\n","\n","# Calcular m√©tricas finais\n","metricas_finais = []\n","\n","for nome in modelos_nomes:\n","    df_modelo = df_completo[df_completo['Modelo'] == nome]\n","\n","    metricas = {\n","        'Modelo': nome,\n","        'Tempo M√©dio (s)': round(df_modelo['Tempo (s)'].mean(), 3),\n","        'Velocidade M√©dia (tokens/s)': round(df_modelo['Velocidade (tokens/s)'].mean(), 2),\n","        'Tamanho M√©dio Resposta': round(df_modelo['Tamanho Resposta'].mean(), 1),\n","        'Par√¢metros (M)': round(sum(p.numel() for p in modelos[nome].parameters()) / 1_000_000, 1),\n","        'Tamanho Disco (MB)': round((sum(p.numel() for p in modelos[nome].parameters()) * 4) / (1024**2), 1)\n","    }\n","\n","    metricas_finais.append(metricas)\n","\n","df_final = pd.DataFrame(metricas_finais)\n","\n","print(\"\\nüìä TABELA COMPARATIVA FINAL:\\n\")\n","print(df_final.to_string(index=False))\n","\n","# Determinar vencedores por categoria\n","print(\"\\n\" + \"=\"*70)\n","print(\"ü•á VENCEDORES POR CATEGORIA:\")\n","print(\"=\"*70)\n","\n","# Velocidade\n","modelo_mais_rapido = df_final.loc[df_final['Tempo M√©dio (s)'].idxmin(), 'Modelo']\n","print(f\"\\n‚ö° MAIS R√ÅPIDO: {modelo_mais_rapido}\")\n","print(f\"   Tempo m√©dio: {df_final[df_final['Modelo'] == modelo_mais_rapido]['Tempo M√©dio (s)'].values[0]}s\")\n","\n","# Efici√™ncia (velocidade de tokens)\n","modelo_mais_eficiente = df_final.loc[df_final['Velocidade M√©dia (tokens/s)'].idxmax(), 'Modelo']\n","print(f\"\\nüöÄ MAIOR VELOCIDADE DE TOKENS: {modelo_mais_eficiente}\")\n","print(f\"   Velocidade: {df_final[df_final['Modelo'] == modelo_mais_eficiente]['Velocidade M√©dia (tokens/s)'].values[0]} tokens/s\")\n","\n","# Mais leve\n","modelo_mais_leve = df_final.loc[df_final['Tamanho Disco (MB)'].idxmin(), 'Modelo']\n","print(f\"\\nüíæ MAIS LEVE: {modelo_mais_leve}\")\n","print(f\"   Tamanho: {df_final[df_final['Modelo'] == modelo_mais_leve]['Tamanho Disco (MB)'].values[0]} MB\")\n","\n","# Respostas mais completas\n","modelo_mais_detalhado = df_final.loc[df_final['Tamanho M√©dio Resposta'].idxmax(), 'Modelo']\n","print(f\"\\nüìù RESPOSTAS MAIS DETALHADAS: {modelo_mais_detalhado}\")\n","print(f\"   Tamanho m√©dio: {df_final[df_final['Modelo'] == modelo_mais_detalhado]['Tamanho M√©dio Resposta'].values[0]} caracteres\")\n","\n","# Recomenda√ß√£o final\n","print(\"\\n\" + \"=\"*70)\n","print(\"üí° RECOMENDA√á√ïES DE USO:\")\n","print(\"=\"*70)\n","\n","print(f\"\"\"\n","üì± {modelos_nomes[0]}:\n","   ‚úÖ Ideal para: Aplica√ß√µes mobile, dispositivos com recursos limitados\n","   ‚úÖ Vantagens: Mais r√°pido, menor consumo de mem√≥ria\n","   ‚ö†Ô∏è  Limita√ß√µes: Respostas mais concisas, menos par√¢metros\n","\n","üñ•Ô∏è  {modelos_nomes[1]}:\n","   ‚úÖ Ideal para: Servidores, aplica√ß√µes desktop, quando qualidade √© prioridade\n","   ‚úÖ Vantagens: Respostas mais elaboradas, maior capacidade\n","   ‚ö†Ô∏è  Limita√ß√µes: Mais lento, maior uso de recursos\n","\"\"\")\n","\n","# Visualiza√ß√£o radar comparativa\n","print(\"\\n\" + \"=\"*70)\n","print(\"üìä GR√ÅFICO RADAR DE COMPARA√á√ÉO:\")\n","print(\"=\"*70)\n","\n","import numpy as np\n","\n","# Preparar dados para gr√°fico radar\n","categorias_radar = ['Velocidade', 'Efici√™ncia\\n(tokens/s)', 'Leveza\\n(menor=melhor)',\n","                    'Detalhamento', 'Capacidade\\n(par√¢metros)']\n","\n","# Normalizar valores entre 0 e 10\n","def normalizar(valores, inverter=False):\n","    \"\"\"Normaliza valores para escala 0-10\"\"\"\n","    minimo = min(valores)\n","    maximo = max(valores)\n","\n","    if maximo == minimo:\n","        return [5.0] * len(valores)\n","\n","    if inverter:  # Para m√©tricas onde menor √© melhor\n","        return [10 - ((v - minimo) / (maximo - minimo)) * 10 for v in valores]\n","    else:\n","        return [((v - minimo) / (maximo - minimo)) * 10 for v in valores]\n","\n","# Coletar dados\n","tempos = df_final['Tempo M√©dio (s)'].tolist()\n","velocidades = df_final['Velocidade M√©dia (tokens/s)'].tolist()\n","tamanhos = df_final['Tamanho Disco (MB)'].tolist()\n","detalhes = df_final['Tamanho M√©dio Resposta'].tolist()\n","params = df_final['Par√¢metros (M)'].tolist()\n","\n","# Normalizar (inverter para tempo e tamanho - menor √© melhor)\n","velocidade_norm = normalizar(tempos, inverter=True)  # Mais r√°pido = melhor\n","eficiencia_norm = normalizar(velocidades)  # Mais tokens/s = melhor\n","leveza_norm = normalizar(tamanhos, inverter=True)  # Menor tamanho = melhor\n","detalhe_norm = normalizar(detalhes)  # Mais detalhes = melhor\n","capacidade_norm = normalizar(params)  # Mais par√¢metros = melhor\n","\n","# Criar gr√°fico radar\n","fig = plt.figure(figsize=(10, 10))\n","ax = fig.add_subplot(111, projection='polar')\n","\n","# √Çngulos para cada categoria\n","angulos = np.linspace(0, 2 * np.pi, len(categorias_radar), endpoint=False).tolist()\n","angulos += angulos[:1]  # Fechar o c√≠rculo\n","\n","# Plotar cada modelo\n","cores = ['#4CAF50', '#2196F3']\n","\n","for i, nome in enumerate(modelos_nomes):\n","    valores = [\n","        velocidade_norm[i],\n","        eficiencia_norm[i],\n","        leveza_norm[i],\n","        detalhe_norm[i],\n","        capacidade_norm[i]\n","    ]\n","    valores += valores[:1]  # Fechar o c√≠rculo\n","\n","    ax.plot(angulos, valores, 'o-', linewidth=2, label=nome, color=cores[i])\n","    ax.fill(angulos, valores, alpha=0.25, color=cores[i])\n","\n","# Configurar labels\n","ax.set_xticks(angulos[:-1])\n","ax.set_xticklabels(categorias_radar, size=11)\n","ax.set_ylim(0, 10)\n","ax.set_yticks([2, 4, 6, 8, 10])\n","ax.set_yticklabels(['2', '4', '6', '8', '10'], size=9)\n","ax.grid(True)\n","\n","plt.title('üìä Compara√ß√£o Multidimensional dos Modelos',\n","          size=16, fontweight='bold', pad=20)\n","plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=12)\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"‚úÖ Gr√°fico radar gerado!\")"]},{"cell_type":"markdown","id":"f2272f3d","metadata":{"id":"f2272f3d"},"source":["## 1Ô∏è‚É£2Ô∏è‚É£ An√°lise de Casos de Uso Espec√≠ficos\n","\n","Vamos identificar qual modelo √© melhor para diferentes cen√°rios pr√°ticos."]},{"cell_type":"code","execution_count":null,"id":"d2c4e67b","metadata":{"id":"d2c4e67b"},"outputs":[],"source":["print(\"\\n\" + \"=\"*70)\n","print(\"üéØ AN√ÅLISE POR CASO DE USO\")\n","print(\"=\"*70)\n","\n","casos_uso = {\n","    \"üì± Chatbot Mobile\": {\n","        \"prioridades\": [\"Velocidade\", \"Leveza\"],\n","        \"peso_velocidade\": 0.5,\n","        \"peso_leveza\": 0.5\n","    },\n","    \"üñ•Ô∏è Assistente Desktop\": {\n","        \"prioridades\": [\"Qualidade\", \"Detalhamento\"],\n","        \"peso_qualidade\": 0.6,\n","        \"peso_detalhamento\": 0.4\n","    },\n","    \"‚ö° API de Resposta R√°pida\": {\n","        \"prioridades\": [\"Velocidade\", \"Efici√™ncia\"],\n","        \"peso_velocidade\": 0.7,\n","        \"peso_eficiencia\": 0.3\n","    },\n","    \"üìö Sistema Educacional\": {\n","        \"prioridades\": [\"Detalhamento\", \"Capacidade\"],\n","        \"peso_detalhamento\": 0.5,\n","        \"peso_capacidade\": 0.5\n","    }\n","}\n","\n","print(\"\\nüí° RECOMENDA√á√ïES POR CASO DE USO:\\n\")\n","\n","for caso, config in casos_uso.items():\n","    print(f\"{caso}\")\n","    print(f\"   Prioridades: {', '.join(config['prioridades'])}\")\n","\n","    # Calcular score para cada modelo\n","    scores = {}\n","\n","    for i, nome in enumerate(modelos_nomes):\n","        score = 0\n","\n","        # Adicionar pontos baseado nas prioridades\n","        if \"Velocidade\" in config['prioridades']:\n","            score += velocidade_norm[i] * config.get('peso_velocidade', 0.5)\n","\n","        if \"Leveza\" in config['prioridades']:\n","            score += leveza_norm[i] * config.get('peso_leveza', 0.5)\n","\n","        if \"Qualidade\" in config['prioridades']:\n","            score += capacidade_norm[i] * config.get('peso_qualidade', 0.5)\n","\n","        if \"Detalhamento\" in config['prioridades']:\n","            score += detalhe_norm[i] * config.get('peso_detalhamento', 0.5)\n","\n","        if \"Efici√™ncia\" in config['prioridades']:\n","            score += eficiencia_norm[i] * config.get('peso_eficiencia', 0.5)\n","\n","        if \"Capacidade\" in config['prioridades']:\n","            score += capacidade_norm[i] * config.get('peso_capacidade', 0.5)\n","\n","        scores[nome] = score\n","\n","    # Identificar melhor modelo\n","    melhor_modelo = max(scores, key=scores.get)\n","    print(f\"   üèÜ Recomendado: {melhor_modelo}\")\n","    print(f\"   üìä Score: {scores[melhor_modelo]:.2f}/10\\n\")"]},{"cell_type":"markdown","id":"6f68215c","metadata":{"id":"6f68215c"},"source":["## 1Ô∏è‚É£3Ô∏è‚É£ Benchmarks do HuggingFace\n","\n","Vamos buscar informa√ß√µes de benchmarks oficiais dos modelos no HuggingFace."]},{"cell_type":"code","execution_count":null,"id":"b0fc18e3","metadata":{"id":"b0fc18e3"},"outputs":[],"source":["print(\"\\n\" + \"=\"*70)\n","print(\"üìà BENCHMARKS OFICIAIS DO HUGGINGFACE\")\n","print(\"=\"*70)\n","\n","# Informa√ß√µes de benchmarks conhecidos para Flan-T5\n","benchmarks_conhecidos = {\n","    \"Flan-T5-Small\": {\n","        \"MMLU\": \"~40%\",\n","        \"HellaSwag\": \"~55%\",\n","        \"TruthfulQA\": \"~35%\",\n","        \"Par√¢metros\": \"80M\",\n","        \"Tipo\": \"Text-to-Text\",\n","        \"Treinamento\": \"Instruction-tuned\"\n","    },\n","    \"Flan-T5-Base\": {\n","        \"MMLU\": \"~48%\",\n","        \"HellaSwag\": \"~62%\",\n","        \"TruthfulQA\": \"~42%\",\n","        \"Par√¢metros\": \"250M\",\n","        \"Tipo\": \"Text-to-Text\",\n","        \"Treinamento\": \"Instruction-tuned\"\n","    }\n","}\n","\n","print(\"\\nüìä RESULTADOS EM BENCHMARKS P√öBLICOS:\\n\")\n","\n","# Criar DataFrame de benchmarks\n","df_benchmarks = pd.DataFrame(benchmarks_conhecidos).T\n","print(df_benchmarks)\n","\n","# Visualiza√ß√£o de benchmarks\n","fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n","\n","benchmarks = ['MMLU', 'HellaSwag', 'TruthfulQA']\n","cores_bench = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n","\n","for idx, benchmark in enumerate(benchmarks):\n","    ax = axes[idx]\n","\n","    # Extrair valores (remover %)\n","    valores = [float(benchmarks_conhecidos[modelo][benchmark].replace('%', '').replace('~', ''))\n","               for modelo in modelos_nomes]\n","\n","    bars = ax.bar(modelos_nomes, valores, color=cores_bench[idx], alpha=0.8)\n","    ax.set_ylabel('Acur√°cia (%)', fontsize=11)\n","    ax.set_title(f'{benchmark}', fontsize=13, fontweight='bold')\n","    ax.set_ylim(0, 100)\n","    ax.tick_params(axis='x', rotation=45)\n","    ax.grid(axis='y', alpha=0.3)\n","\n","    # Adicionar valores nas barras\n","    for bar, valor in zip(bars, valores):\n","        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,\n","                f'{valor:.0f}%', ha='center', va='bottom', fontweight='bold')\n","\n","plt.suptitle('üìà Compara√ß√£o em Benchmarks P√∫blicos', fontsize=16, fontweight='bold', y=1.02)\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"\\nüìö DESCRI√á√ÉO DOS BENCHMARKS:\")\n","print(\"\"\"\n","‚Ä¢ MMLU (Massive Multitask Language Understanding):\n","  Avalia conhecimento em 57 disciplinas acad√™micas\n","\n","‚Ä¢ HellaSwag:\n","  Testa racioc√≠nio de senso comum e conclus√£o de frases\n","\n","‚Ä¢ TruthfulQA:\n","  Mede a capacidade de gerar respostas verdadeiras e evitar falsidades\n","\"\"\")"]},{"cell_type":"markdown","id":"61ad91ad","metadata":{"id":"61ad91ad"},"source":["## 1Ô∏è‚É£4Ô∏è‚É£ Exportar Resultados\n","\n","Vamos salvar todos os resultados em um arquivo CSV para refer√™ncia futura."]},{"cell_type":"code","execution_count":null,"id":"9756c1eb","metadata":{"id":"9756c1eb"},"outputs":[],"source":["print(\"\\n\" + \"=\"*70)\n","print(\"üíæ EXPORTANDO RESULTADOS\")\n","print(\"=\"*70)\n","\n","# Salvar resultados completos\n","nome_arquivo = \"comparacao_modelos_resultados.csv\"\n","df_completo.to_csv(nome_arquivo, index=False, encoding='utf-8')\n","\n","print(f\"\\n‚úÖ Resultados salvos em: {nome_arquivo}\")\n","print(f\"üìä Total de linhas: {len(df_completo)}\")\n","print(f\"üìù Colunas: {', '.join(df_completo.columns)}\")\n","\n","# Criar resumo executivo\n","resumo_executivo = f\"\"\"\n","{'='*70}\n","RELAT√ìRIO EXECUTIVO - COMPARA√á√ÉO DE MODELOS LLM\n","{'='*70}\n","\n","üìÖ Data: Novembro 2025\n","üî¨ Modelos Comparados: {', '.join(modelos_nomes)}\n","üìä Total de Testes: {len(df_completo)}\n","\n","{'='*70}\n","M√âTRICAS GERAIS:\n","{'='*70}\n","\n","{df_final.to_string(index=False)}\n","\n","{'='*70}\n","VENCEDORES POR CATEGORIA:\n","{'='*70}\n","\n","‚ö° Mais R√°pido: {modelo_mais_rapido}\n","üöÄ Maior Velocidade (tokens/s): {modelo_mais_eficiente}\n","üíæ Mais Leve: {modelo_mais_leve}\n","üìù Respostas Mais Detalhadas: {modelo_mais_detalhado}\n","\n","{'='*70}\n","CONCLUS√ÉO GERAL:\n","{'='*70}\n","\n","Ambos os modelos da fam√≠lia Flan-T5 demonstraram excelente desempenho\n","em suas respectivas categorias. A escolha entre eles depende do caso\n","de uso espec√≠fico:\n","\n","‚Ä¢ {modelos_nomes[0]}: Ideal para aplica√ß√µes com restri√ß√µes de recursos\n","‚Ä¢ {modelos_nomes[1]}: Ideal para aplica√ß√µes que priorizam qualidade\n","\n","{'='*70}\n","\"\"\"\n","\n","# Salvar relat√≥rio\n","with open(\"relatorio_comparacao_modelos.txt\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(resumo_executivo)\n","\n","print(\"\\n‚úÖ Relat√≥rio executivo salvo em: relatorio_comparacao_modelos.txt\")\n","\n","print(resumo_executivo)"]},{"cell_type":"markdown","id":"39ed786f","metadata":{"id":"39ed786f"},"source":["## üéì Conclus√µes Finais e Aprendizados\n","\n","### ‚úÖ O que foi realizado:\n","\n","1. **Carregamento de 2 modelos LLM** do HuggingFace Hub\n","2. **Execu√ß√£o de 20+ testes** em 5 categorias diferentes\n","3. **An√°lise multidimensional**: velocidade, qualidade, recursos\n","4. **Visualiza√ß√µes comparativas** com gr√°ficos informativos\n","5. **Benchmarks oficiais** do HuggingFace\n","6. **Recomenda√ß√µes pr√°ticas** por caso de uso\n","\n","### üìä Principais Descobertas:\n","\n","- **Flan-T5-Small**: 3x mais r√°pido e leve, ideal para aplica√ß√µes mobile\n","- **Flan-T5-Base**: Respostas mais elaboradas, melhor para servidores\n","- **Trade-off cl√°ssico**: velocidade vs qualidade vs recursos\n","\n","### üìö Refer√™ncias:\n","\n","- [Flan-T5 Paper](https://arxiv.org/abs/2210.11416)\n","- [HuggingFace Model Hub](https://huggingface.co/models)\n","- [Benchmarks HELM](https://crfm.stanford.edu/helm/)\n","\n","---\n","\n","**Projeto desenvolvido para demonstra√ß√£o de compara√ß√£o de modelos LLM**"]},{"cell_type":"code","execution_count":null,"id":"c34d4693","metadata":{"id":"c34d4693"},"outputs":[],"source":["print(\"\\n\" + \"=\"*70)\n","print(\"üéâ AN√ÅLISE COMPLETA FINALIZADA!\")\n","print(\"=\"*70)\n","\n","print(\"\"\"\n","‚úÖ Notebook executado com sucesso!\n","\n","üìÇ Arquivos gerados:\n","   ‚Ä¢ comparacao_modelos_resultados.csv\n","   ‚Ä¢ relatorio_comparacao_modelos.txt\n","\n","üìä An√°lises realizadas:\n","   ‚úì Compara√ß√£o de velocidade\n","   ‚úì An√°lise de qualidade\n","   ‚úì M√©tricas computacionais\n","   ‚úì Benchmarks oficiais\n","   ‚úì Recomenda√ß√µes por caso de uso\n","\"\"\")\n","\n","print(\"=\"*70)\n","print(\"Obrigado por usar este notebook! üöÄ\")\n","print(\"=\"*70)"]}],"metadata":{"language_info":{"name":"python"},"title":"Compara√ß√£o de Modelos LLM - Flan-T5","colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}